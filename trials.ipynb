{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "second-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import grad\n",
    "from torch.autograd.functional import jacobian\n",
    "from operators import Δ, div, D, mdotb, bdotm, mdotm, bdotb\n",
    "from torch.nn.functional import relu, max_pool2d, avg_pool2d, dropout, dropout2d, interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "restricted-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Complex_ReLU(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return relu(input.real).type(torch.complex64)+1j*relu(input.imag).type(torch.complex64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "meaning-salon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1237+0.7677j],\n",
       "        [-0.8950-1.2208j],\n",
       "        [-0.2374-1.4870j],\n",
       "        [ 0.8238+0.1815j]], grad_fn=<UnsqueezeBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complex_net = nn.Sequential(\n",
    "            nn.Linear(1, 4).to(torch.cfloat),\n",
    "            Complex_ReLU(),\n",
    "            nn.Linear(4, 1).to(torch.cfloat)\n",
    "        )\n",
    "tensor = torch.randn(4, 2).requires_grad_()\n",
    "tensor\n",
    "torch.view_as_complex(tensor).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "circular-treaty",
   "metadata": {},
   "outputs": [],
   "source": [
    "u = complex_net(torch.view_as_complex(tensor).unsqueeze(1))\n",
    "u = torch.exp(torch.abs(1j*u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "whole-crack",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/frederik/anaconda3/envs/dgm_env/lib/python3.8/site-packages/torch/autograd/__init__.py:223: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at  /pytorch/aten/src/ATen/native/Copy.cpp:219.)\n",
      "  return Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0384,  0.0527],\n",
       "        [ 0.1280, -0.1532],\n",
       "        [-0.0318, -0.1729],\n",
       "        [-0.0388,  0.0143]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div(u, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "virgin-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = torch.tensor([[1.0, 1.0],\n",
    "                   [4.0, 3.0]], requires_grad=True)\n",
    "t = torch.tensor([[2.0], \n",
    "                  [3.0]], requires_grad=True)\n",
    "\n",
    "var_2 = torch.tensor([[1.0],\n",
    "                   [3.0]], requires_grad=True)\n",
    "t_2 = torch.tensor([[1.0], \n",
    "                  [2.0]], requires_grad=True)\n",
    "def u(x, t):\n",
    "    xt = torch.cat((x, t), dim=1)\n",
    "    return (1/6)*torch.pow(xt[:, 0].unsqueeze(1), 3) + xt[:,-1].unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_net = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(4, 4),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(4, 1)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = u(var, t)\n",
    "out_2 = u(var_2, t_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(jacobian(spatial_net, var), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-routine",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = spatial_net(var)\n",
    "div(out, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sized-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(div(out.unsqueeze(1), t))\n",
    "print(div(out_2.unsqueeze(1), t_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-freeware",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(div(out.unsqueeze(1), var))\n",
    "print(div(out_2.unsqueeze(1), var_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "later-shore",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Δ(out.unsqueeze(1), var))\n",
    "print(Δ(out_2.unsqueeze(1), var_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-december",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.square(div(out, t) - Δ(out, var)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "civic-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_1 = torch.tensor([[1.0],\n",
    "                      [4.0]], requires_grad=True)\n",
    "var_2 = torch.tensor([[2.0],\n",
    "                      [8.0]], requires_grad=True)\n",
    "var = [var_1, var_2]\n",
    "C = torch.tensor([[2.0, 4.0],\n",
    "                  [1.0, 3.0]], requires_grad=True)\n",
    "def u(x, t):\n",
    "    xt = torch.cat((x, t), dim=1)\n",
    "    return (1/6)*torch.pow(xt[:, 0].unsqueeze(1), 3) + torch.pow(xt[:,-1].unsqueeze(1), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "vanilla-tongue",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 4.1667],\n",
      "        [74.6667]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "us = u(var_1, var_2)\n",
    "print(us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "veterinary-paint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5000],\n",
       "        [8.0000]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D(us, var_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "driving-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Infix:\n",
    "    def __init__(self, function):\n",
    "        self.function = function\n",
    "    def __ror__(self, other):\n",
    "        return Infix(lambda x, self=self, other=other: self.function(other, x))\n",
    "    def __or__(self, other):\n",
    "        return self.function(other)\n",
    "    def __rlshift__(self, other):\n",
    "        return Infix(lambda x, self=self, other=other: self.function(other, x))\n",
    "    def __rshift__(self, other):\n",
    "        return self.function(other)\n",
    "    def __call__(self, value1, value2):\n",
    "        return self.function(value1, value2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "higher-steps",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_func(x, y):\n",
    "    if isinstance(x, list):\n",
    "        x = torch.cat(x, dim=-1)   \n",
    "        return torch.einsum(\"bi, ij -> bj\", x, y)\n",
    "    y = torch.cat(y, dim=-1)\n",
    "    return torch.einsum(\"ij, bj -> bi\", x, y)\n",
    "        \n",
    "def v_func(x, y):\n",
    "    if isinstance(x, list):\n",
    "        x = torch.cat(x, dim=-1)\n",
    "    if isinstance(y, list):\n",
    "        y = torch.cat(y, dim=-1)\n",
    "    \n",
    "    return torch.einsum(\"bi, bi -> b\", x, y).unsqueeze(1)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pressed-regular",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_1 = torch.tensor([[1.0],\n",
    "                      [4.0],\n",
    "                      [4.0]], requires_grad=True)\n",
    "var_2 = torch.tensor([[2.0],\n",
    "                      [8.0],\n",
    "                      [3.0]], requires_grad=True)\n",
    "var_3 = torch.tensor([[1.0],\n",
    "                      [1.0],\n",
    "                      [1.0]], requires_grad=True)\n",
    "var = [var_1, var_2, var_3]\n",
    "C = torch.tensor([[2.0, 4.0],\n",
    "                  [1.0, 3.0]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "located-penny",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.,  7.],\n",
       "        [40., 28.],\n",
       "        [20., 13.]], grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(C @ torch.cat(var[:2], dim=-1).T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "grave-million",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.,  7.],\n",
       "        [40., 28.],\n",
       "        [20., 13.]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(C |mdotb| torch.cat(var[:2], dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "portable-firmware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 1.],\n",
       "        [4., 8., 4.],\n",
       "        [4., 3., 4.]], grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((var_1, var_2, var_1), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alleged-color",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
