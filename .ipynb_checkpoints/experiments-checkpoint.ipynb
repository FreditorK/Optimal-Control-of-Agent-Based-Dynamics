{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "south-stationery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.autograd import grad\n",
    "from torch.autograd.functional import hessian, jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "special-listening",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = torch.tensor([[[1.0],\n",
    "                    [2.0],\n",
    "                    [3.0]]], requires_grad=True)\n",
    "t = torch.tensor([[[5.0]]], requires_grad=True)\n",
    "u = lambda x, t: torch.sum(torch.pow(x, 2), dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "imported-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "#out = u(var, t)\n",
    "#div = torch.sum(grad(outputs=out, inputs=var, grad_outputs=torch.ones_like(out))[0], dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cubic-hormone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[14.]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = u(var, t)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "golden-tongue",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Î”(u, vars):\n",
    "    u_gradient = grad(outputs=u, inputs=vars, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    u_laplacian = torch.sum([grad(u_gradient_i, vars_i, create_graph=True) for u_gradient_i, vars_i in zip(vars, u_gradient)])\n",
    "    return u_laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "invisible-possibility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u_gradient = grad(outputs=out, inputs=var, grad_outputs=torch.ones_like(out), create_graph=True)[0]\\nu_gradient = u_gradient.flatten(start_dim=1)\\nvar = var.flatten()\\n[grad(u_gradient_i, vars_i, create_graph=True)[0] for u_gradient_i, vars_i in zip(var[:], (u_gradient[..., i] for i in range(len(var))))]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''u_gradient = grad(outputs=out, inputs=var, grad_outputs=torch.ones_like(out), create_graph=True)[0]\n",
    "u_gradient = u_gradient.flatten(start_dim=1)\n",
    "var = var.flatten()\n",
    "[grad(u_gradient_i, vars_i, create_graph=True)[0] for u_gradient_i, vars_i in zip(var[:], (u_gradient[..., i] for i in range(len(var))))]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "compact-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def laplace(fx: torch.Tensor, x: torch.Tensor):\n",
    "    dfx = torch.autograd.grad(fx, x, create_graph=True)[0]\n",
    "    ddfx = []\n",
    "    for i in range(x.shape[0]):\n",
    "        vec = torch.zeros_like(dfx)\n",
    "        vec[i]=1\n",
    "        ddfx += [torch.autograd.grad(\n",
    "            dfx,\n",
    "            x,\n",
    "            create_graph=True,\n",
    "            grad_outputs=vec\n",
    "        )[0][i]]\n",
    "    ret = np.sum(ddfx)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "simplified-trauma",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sum(): argument 'input' (position 1) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-0c46078c2155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlaplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-0e84cc61658f>\u001b[0m in \u001b[0;36mlaplace\u001b[0;34m(fx, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         )[0][i]]\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddfx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sum(): argument 'input' (position 1) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "laplace(out, var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hundred-dream",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.autograd.grad(out, var, create_graph=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-appliance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "working-welding",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
