{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "interracial-custom",
   "metadata": {},
   "source": [
    "# Solving Hamilton-Jacobi-Bellman Equations (Deep Galerkin)\n",
    "#### Frederik Kelbel, Imperial College London"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-event",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "encouraging-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "from operators import div, Δ, D, mdotb, bdotm, mdotm, bdotb, cat\n",
    "from DGM import DGMPIASolver, DeepPDESolver\n",
    "from pdes import HBJ, PDE\n",
    "from scipy.integrate import quad\n",
    "from plotly.subplots import make_subplots\n",
    "from configs import CONFIG_HBJS as MODEL_CONFIG\n",
    "from itertools import product\n",
    "from sampling import PATH_SPACES\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-superior",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-trademark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_losses(losses, avg_over=10):\n",
    "    avgs_1 = np.convolve(losses[:, 0], np.ones(avg_over), 'valid') / avg_over\n",
    "    avgs_2 = np.convolve(losses[:, 1], np.ones(avg_over), 'valid') / avg_over\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(avgs_1)), y=avgs_1, mode='lines', name=\"Value Loss\"), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(avgs_2)), y=avgs_2, mode='lines', name=\"Control Loss\"), row=1, col=1)\n",
    "    fig.update_layout(\n",
    "        title=\"Loss\",\n",
    "        xaxis_title=\"Iterations\",\n",
    "        yaxis_title=\"Loss\",\n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=14\n",
    "        )\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "def plot_value(solver, sol):\n",
    "    fig = make_subplots(rows=1, cols=2, \n",
    "                   specs=[[{'type': 'surface'}, {'type': 'surface'}]])\n",
    "    xs = np.linspace(0, 1, 100)\n",
    "    ts = np.linspace(0.01, 1, 100)\n",
    "    us_pred = np.array([[solver(x, t).item() for x in xs] for t in ts])\n",
    "    us = np.array([[sol(x, t) for x in xs] for t in ts])\n",
    "    fig.add_trace(go.Surface(z=us, showscale=False), row=1, col=1)\n",
    "    fig.add_trace(go.Surface(z=us_pred), row=1, col=2)\n",
    "    fig.update_layout(title='Solution | Approximation',\n",
    "                  scene = dict(\n",
    "                    xaxis_title=\"t\",\n",
    "                    yaxis_title=\"x\",\n",
    "                    zaxis_title=\"J(x, t\"),\n",
    "                  scene2 = dict(\n",
    "                    xaxis_title=\"t\",\n",
    "                    yaxis_title=\"x\",\n",
    "                    zaxis_title=\"J(x, t)\"),\n",
    "                  margin=dict(l=50, r=50, b=50, t=50))\n",
    "    fig.show()\n",
    "    \n",
    "def plot_loss(losses, avg_over=10):\n",
    "    avgs = np.convolve(losses, np.ones(avg_over), 'valid') / avg_over\n",
    "    fig = make_subplots(rows=1, cols=1)\n",
    "    fig.add_trace(go.Scatter(x=np.arange(len(avgs)), y=avgs, mode='lines', name=\"Error at x=0.1\"), row=1, col=1)\n",
    "    fig.update_layout(\n",
    "        title=\"Loss\",\n",
    "        xaxis_title=\"Iterations\",\n",
    "        yaxis_title=\"Loss\",\n",
    "        font=dict(\n",
    "            family=\"Courier New, monospace\",\n",
    "            size=14\n",
    "        )\n",
    "    )\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interracial-weight",
   "metadata": {},
   "source": [
    "## Problem Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "needed-helen",
   "metadata": {},
   "source": [
    "Objective: Find the control process $u = (u_t)_{t \\geq 0}$ in admissable set $\\mathcal{A}$ for an Itô Process $X^u = (X_t^u)_{t \\geq 0}$ satisfying:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blond-elder",
   "metadata": {},
   "source": [
    "$$\n",
    "d X_t^u = \\mu(t, X_t^u, u_t) dt + \\sigma(t, X_t^u, u_t) d W_t, \\quad X_0^u = 0.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceramic-embassy",
   "metadata": {},
   "source": [
    "We will consider the HBJ-Equations in their primal form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first-november",
   "metadata": {},
   "source": [
    "The agents performance is assessed via:\n",
    "$$\n",
    "J^u(t, x) = \\mathbb{E}\\Big[ \\int_t^T F(s, X_s^u, u_s) ds + G(X_T^u) \\;\\Big|\\; X_t^u = x \\Big]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-burst",
   "metadata": {},
   "source": [
    "Denote $J(t, x) = \\sup_{u \\in \\mathcal{A}} J^u(t, x)$, then this value function satisfies the following HJB-equations:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-jacob",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{cases}\n",
    "\\partial_t J(t, x) + \\sup_{u \\in \\mathcal{A}} \\{\\mathscr{L}^u_t J(t, x) + F(t, x, u)\\} = 0 \\\\\n",
    "J(T, x) = G(x)\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-ballet",
   "metadata": {},
   "source": [
    "### The Merton Problem (Wealth Allocation Problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limiting-bruce",
   "metadata": {},
   "source": [
    "The goal is to find the optimal wealth allocation strategy over time such that the wealth itself is maximized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-municipality",
   "metadata": {},
   "source": [
    "Consider a market with a risky and risk-free asset. Suppose the value of the risk-free asset at time $t$ is given by $\\frac{d B_t}{B_t} = r dt$ or $B_t = B_0 e^{rt}, t\\geq 0$. Additionally, we have that the risky asset evolves accordingly to $\\frac{d S_t}{S_t} = \\mu dt + \\sigma dW_t$, where $\\{W_t\\}_{t\\geq 0}$ is a standard one-dimensional Brownian motion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marked-supplement",
   "metadata": {},
   "source": [
    "The wealth can then be described by\n",
    "$$\n",
    "X_t= x + \\int_0^t v_s \\frac{dS_s}{S_s} + \\int_0^t(X_s-v_s)\\frac{dB_s}{B_s},\n",
    "$$\n",
    "where $v_t = u_t X_t$ describes the amount of the wealth to be have invested into the risky asset at time $t$. $u_t$ is the fraction of wealth invested in the risky asset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-subcommittee",
   "metadata": {},
   "source": [
    "Let $(\\Omega, \\mathcal{F}, \\{\\mathcal{F}_t\\}_{t\\in [0, T]}, \\mathbb{P})$ be a filtered probability space. The evolution of an investor's wealth is described via\n",
    "$$\n",
    "\\begin{cases}\n",
    "dX_s = ((\\mu -r)u_s + r)X_s ds + \\sigma u_s X_s dW_s, \\; s \\in [0, T] \\\\\n",
    "X_0 = x > 0\n",
    "\\end{cases},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-perry",
   "metadata": {},
   "source": [
    "with $\\mu>r$ and $\\sigma>0$ referring to drift and volatility, respectively. Let $r>0$ denote the discount rate, i.e. the depreciation constant. The intent is to maximise the objective\n",
    "$$\n",
    "J^u(t, X_t) = \\mathbb{E}[ X_T^\\gamma ], \\; \\gamma \\in(0, 1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-sight",
   "metadata": {},
   "source": [
    "The respective HBJ-equation becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-potential",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{cases}\n",
    "\\partial_t J(t, x) + \\sup_{u} \\Big\\{ ((\\mu-r)u + r)x \\partial_x J(t, x) + \\frac{1}{2} \\sigma^2 u^2 x^2\\partial_{xx} J(t, x) \\Big\\} = 0 \\text{ on $[0, T] \\times (0, \\infty)$}\n",
    "\\\\\n",
    "J(T, x) = x^\\gamma \\text{ $\\forall x > 0$}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "manufactured-cambodia",
   "metadata": {},
   "source": [
    "#### Analytical Solution (Oksendal):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crude-limitation",
   "metadata": {},
   "source": [
    "Assume $J(t, x) = w(t) v(x)$, with $J(T, x) = w(T) v(x) = x^\\gamma$. We guess $J(t, x) = w(t) x^\\gamma$, where $w(T)=1$. The problem becomes \n",
    "$$\n",
    "\\begin{cases}\n",
    "w'(t) + \\gamma  \\sup_{u} \\Big\\{ (\\mu-r) u + r + \\frac{1}{2} \\sigma^2 u^2 (\\gamma-1) \\Big\\}w(t) = 0\n",
    "\\\\\n",
    "w(T) = x^\\gamma\n",
    "\\end{cases}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-transsexual",
   "metadata": {},
   "source": [
    "Then, $u$ is maximised for $u^* = \\frac{\\mu-r}{\\sigma^2 (1-\\gamma)}$ and the equation becomes\n",
    "$$\n",
    "\\begin{cases}\n",
    "w'(t) + \\frac{\\gamma (\\mu-r)^2}{\\sigma^2(2-2\\gamma)}w(t) = 0\n",
    "\\\\\n",
    "w(T) = x^\\gamma\n",
    "\\end{cases}.\n",
    "$$\n",
    "Thus, we have  $w'(t) = \\frac{\\gamma (\\mu-r)^2}{\\sigma^2(2\\gamma - 2)}w(t)$. It follows that $w(t) = \\exp\\big(\\frac{\\gamma (\\mu-r)^2}{\\sigma^2(2\\gamma - 2)}t\\big)$. The final solution is:\n",
    "$$\n",
    "J(t, x) = w(t)v(x) = \\exp\\big(\\frac{\\gamma (\\mu-r)^2}{\\sigma^2(2\\gamma - 2)}t\\big) x^\\gamma.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-garden",
   "metadata": {},
   "source": [
    "We need to verify this using the HBJ-verification theorem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RISKY_ASSET(HBJ):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.μ = 0.04\n",
    "        self.σ = 0.4\n",
    "        self.r = 0.03\n",
    "        self.γ = 0.8\n",
    "        \n",
    "        self.var_dim_J = 2 # (x, t)\n",
    "        self.control_vars = [1] # (t)\n",
    "        self.cost_function = lambda u, var: 0\n",
    "        self.differential_operator = lambda J, u, var: ((self.μ-self.r)*u+self.r)*var[0]*div(J, var[0]) + 0.5*self.σ**2*u**2*var[0]**2*Δ(J, var[0])\n",
    "        self.domain_func = [(lambda var: var, 128)]\n",
    "        self.boundary_cond_J = [lambda J, var: J - var[0]**self.γ]\n",
    "        self.boundary_func_J = [(lambda var: [var[0], 0*var[1] + 1], 128)]\n",
    "        self.boundary_cond_u = [lambda u, var: torch.clamp(u, min=1) - torch.clamp(u, max=-1) - 2]\n",
    "        self.boundary_func_u = [(lambda var: var, 64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-roman",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = RISKY_ASSET()\n",
    "model = MODEL_CONFIG\n",
    "solver = DGMPIASolver(model, eq)\n",
    "loss = np.array(list(solver.train(800)))\n",
    "plot_losses(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuffed-moderator",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_sol = lambda t : (eq.μ-eq.r)/(eq.σ**2*(1-eq.γ))\n",
    "J_sol = lambda x, t: x**eq.γ * np.exp((eq.γ*(eq.μ-eq.r)**2)/(eq.σ**2*(2*eq.γ-2))*t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exciting-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1)\n",
    "eval_points = np.linspace(0, 1, 100)\n",
    "fig.add_trace(go.Scatter(x=eval_points, y=[solver.u(p)[0] for p in eval_points], mode='lines', name=\"Optimal Control\"), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=eval_points, y=[u_sol(p) for p in eval_points], mode='lines', name=\"Optimal Control Solution\"), row=1, col=1)\n",
    "fig.update_layout(\n",
    "    title=\"Solutions\",\n",
    "    xaxis_title=\"Time\",\n",
    "    yaxis_title=\"Control Signal\",\n",
    "    yaxis_range=[0, 1],\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=14\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_value(solver.J, J_sol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-pricing",
   "metadata": {},
   "source": [
    "### Optimal Liquidation Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-camping",
   "metadata": {},
   "source": [
    "Let us consider an asset $S_t$, that evolves accordingly with Brownian motion, i.e. $dS_s = -B u_s ds + \\sigma dW_s$. Assume that we hold a certain amount of this asset and intend to liquidate it over the time period $s \\in [0, T]$. Let $Q$ be our inventory of the asset with $dQ_s = - u_s ds$ (with $Q(0)=N$), where $u_s$ represents the liquidation rate. Suppose the temporary price impact is linear (the cost of selling), then our cash $X_s$ is modelled by \n",
    "$$\n",
    "X_t = x + \\int_0^t S_s u_s ds -\\int_0^t D u_s^2 + C q^2ds \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-syracuse",
   "metadata": {},
   "source": [
    "We aim to maximise\n",
    "$$\n",
    "J^u(t, S, q) := \\mathbb{E}^{t, S} \\Big[ \\int_t^T S_s u_s -Du_s^2 - Cq^2 ds + S_T q_T- R q_T^2\\Big],\n",
    "$$\n",
    "subject to the process\n",
    "$$\\begin{eqnarray}\n",
    "dS_s &=& -Bu_s ds + \\sigma dW_s \\\\ \n",
    "dQ_s &=& - u_s ds\n",
    "\\end{eqnarray}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-interface",
   "metadata": {},
   "source": [
    "Thus, the HBJ-Equation is given as:\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\partial_t J(t, S, q) + \\sup_{u} \\Big\\{ u_s(S-Du_s) - Cq^2 + ( \\frac{1}{2} \\sigma^2 \\partial_{SS} - B u_s \\partial_S - u_s \\partial_q)J(t, S, q)  \\Big\\} = 0 \\text{ on $[0, T] \\times (0, \\infty)\\times [0, N]$}\n",
    "\\\\\n",
    "J(T, S, q) = Sq - R q^2 \\text{ $\\forall x \\in \\mathbb{R}$}\n",
    "\\end{cases},\n",
    "$$\n",
    "where $R$ is the terminal cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incident-romantic",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIQUIDATION(HBJ):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.σ = 0.3\n",
    "        self.D = 0.05\n",
    "        self.C = 0.1\n",
    "        self.R = self.D + self.C\n",
    "        self.B = 0.0001\n",
    "        \n",
    "        \n",
    "        self.var_dim_J = 4 # (S, q, X, t)\n",
    "        self.control_vars = [0, 1, 2, 3] # (S ,q, X, t)\n",
    "        self.cost_function = lambda u, var: 0\n",
    "        self.differential_operator = lambda J, u, var: 0.5*self.σ**2*Δ(J, var[0]) -self.B*u*div(J, var[0]) - u*div(J, var[1]) + (var[0]*u - self.C*var[1]**2 - self.D*u**2)*div(J, var[2])\n",
    "        self.domain_func = [(lambda var: [(var[0]-0.5)*4, (var[1]-0.4)*4, (var[2]-0.5)*4, var[3]], 64)]\n",
    "        self.boundary_cond_J = [lambda J, var: J - (var[2] + var[0]*var[1]-self.R*var[1]**2)]\n",
    "        self.boundary_func_J = [(lambda var: [(var[0]-0.5)*4, (var[1]-0.4)*4, (var[2]-0.5)*4, var[3]*0 + 1], 64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dental-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIQUIDATION_MODEL_CONFIG = {\n",
    "    \"hidden_dim\": 32,\n",
    "    \"learning_rate\": 5e-3,\n",
    "    \"loss_weights\": (1, 1),\n",
    "    \"lr_decay\": 0.99,\n",
    "    \"sampling_method\": \"uniform\",\n",
    "    \"network_type\": \"FF\",\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"delay_control\": 2,\n",
    "    \"alpha_noise\": 0.3\n",
    "}\n",
    "eq = LIQUIDATION()\n",
    "model = LIQUIDATION_MODEL_CONFIG\n",
    "solver = DGMPIASolver(model, eq)\n",
    "loss = np.array(list(solver.train(500)))\n",
    "plot_losses(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "c_xs = np.zeros(n)\n",
    "c_Ss = np.zeros(n)\n",
    "c_Q = np.zeros(n)\n",
    "c_xs[0] = 0.3\n",
    "c_Ss[0] = 0.5\n",
    "c_Q[0] = 1.0\n",
    "uc_xs = np.zeros(n)\n",
    "uc_Ss = np.zeros(n)\n",
    "uc_xs[0] = c_xs[0]\n",
    "uc_Ss[0] = c_Ss[0]\n",
    "dt = 1/n\n",
    "ts = [t for t in np.linspace(0, 1, n)]\n",
    "c_value = np.zeros(n)\n",
    "for i in range(n-1):\n",
    "    dW = np.sqrt(dt)*np.random.randn()\n",
    "    c = solver.u(c_Ss[i], c_Q[i], c_xs[i], i*dt).item()\n",
    "    c_value[i] = solver.J(c_Ss[i], c_Q[i], c_xs[i], i*dt).item()\n",
    "    c_Q[i+1] = c_Q[i] - c*dt\n",
    "    c_Ss[i+1] = c_Ss[i] -eq.B*c*dt + eq.σ*dW\n",
    "    uc_Ss[i+1] = uc_Ss[i] + eq.σ*dW\n",
    "    c_xs[i+1] = c_xs[i] + c_Ss[i]*c*dt - eq.D*c**2*dt - eq.C*c_Q[i]**2*dt\n",
    "    uc_xs[i+1] = uc_xs[i] - eq.C*c_Q[0]**2*dt\n",
    "\n",
    "c_value[-1] = solver.J(c_Ss[-1], c_Q[-1], c_xs[-1], n*dt).item()\n",
    "c_xs[-1] += c_Ss[-1]*c_Q[-1] - eq.R*c_Q[-1]**2\n",
    "uc_xs[-1] += uc_Ss[-1]*c_Q[0] - eq.R*c_Q[0]**2\n",
    "    \n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_trace(go.Scatter(x=ts, y=c_xs, mode='lines', name=\"Controlled\", line=dict(color=\"#00e476\")), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=ts, y=uc_xs, mode='lines', name=\"Uncontrolled\", line=dict(color=\"#FFe476\")), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=ts, y=c_Ss, mode='lines', name=\"Value Function\", line=dict(color=\"#eeee76\")), row=1, col=1)\n",
    "fig.update_layout(\n",
    "    title=\"Maximise amount of X\",\n",
    "    xaxis_title=\"t\",\n",
    "    yaxis_title=\"X\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=14\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-paradise",
   "metadata": {},
   "source": [
    "### Linear-quadratic control problem 1-dimensional (Riccati Equation) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-emerald",
   "metadata": {},
   "source": [
    "Let $(\\Omega, \\mathcal{F}, \\{\\mathcal{F}_t\\}_{t\\in [0, T]}, \\mathbb{P})$. We consider\n",
    "$$\n",
    "\\begin{cases}\n",
    "dX_s = [H_sX_s + M_s u_s] ds + \\sigma_s dW_s, \\; s \\in [0, T] \\\\\n",
    "X_0 = x > 0\n",
    "\\end{cases},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-vegetarian",
   "metadata": {},
   "source": [
    "We aim to maximise\n",
    "$$\n",
    "J^u(t, x) := \\mathbb{E}^{t, x} \\Big[ \\int_t^T X_s^T C_s X_s + u_s^T D_s u_s ds + X_T^T R X_T\\Big],\n",
    "$$\n",
    "with $C(t) = C \\leq 0, R \\leq 0$, and $D=D(t) < -\\delta < 0$ given and deterministic ($\\delta > 0$ some constant)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mathematical-internship",
   "metadata": {},
   "source": [
    "We write down the problem in its primal form as\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\partial_t J(t, x) + \\sup_{u} \\Big\\{ \\frac{1}{2} \\sigma^2 \\partial_{xx} J(t, x) + [H x + M u] \\partial_x J(t, x) + C x^2 + D u^2 \\Big\\} = 0 \\text{ on $[0, T] \\times (-\\infty, \\infty)$}\n",
    "\\\\\n",
    "J(T, x) = Rx^2 \\text{ $\\forall x \\in \\mathbb{R}$}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-asbestos",
   "metadata": {},
   "source": [
    "#### Analytical Solution (Oksendal):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-diary",
   "metadata": {},
   "source": [
    "As $J(T, x) = Rx^2$, we assume the form $J(T, x) = S(t) x^2 + b(t)$ for some differentibale $S$ and $b$. The problem can be reformulated as\n",
    "$$\n",
    "\\begin{cases}\n",
    "S'(t)x^2 + b'(t) + \\sigma^2 S(t) + 2HS(t)x^2 + C x^2 + \\sup_{u} \\Big\\{ 2MS(t) u x + D u^2 \\Big\\} = 0 \\text{ on $[0, T] \\times (0, \\infty)$}\n",
    "\\\\\n",
    "S(T) = R, b(t)=0 \\text{ $\\forall x \\in \\mathbb{R}$}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-knife",
   "metadata": {},
   "source": [
    "We see that for fixed $t$ and $x$, we have $u^*=u^*(t, x)=-D^{-1} MS(t) x$. As a consequence, we can transform the problem to be gives as\n",
    "$$\n",
    "\\begin{cases}\n",
    "[S'(t) + 2HS(t) + C - D^{-1} M^2S^2(t)]x^2 + b'(t) + \\sigma^2 S(t) = 0 \\text{ on $[0, T] \\times (0, \\infty)$}\n",
    "\\\\\n",
    "S(T) = R, b(t)=0 \\text{ $\\forall x \\in \\mathbb{R}$}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-integer",
   "metadata": {},
   "source": [
    "The problem is satisfied if\n",
    "$$\n",
    "S'(t)= D^{-1} M^2S^2(t) - C - 2HS(t), \\; S(T)=R \\; \\text{(Riccati Equation)}\n",
    "$$\n",
    "$$\n",
    "b'(t)= -\\sigma^2 S(t), \\; b(T)=0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laden-blank",
   "metadata": {},
   "source": [
    "It follows that $b(t)=  \\sigma^2 \\int_t^T S(r) dr$, while the Riccati Equation has a unique solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LQR(HBJ):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.H = 0.1\n",
    "        self.M = 2.0\n",
    "        self.C = -2.0\n",
    "        self.R = -0.001\n",
    "        self.D = -0.2\n",
    "        self.σ = 0.3\n",
    "        \n",
    "        self.var_dim_J = 2 # (x, t)\n",
    "        self.control_vars = [0, 1]\n",
    "        self.cost_function = lambda u, var: self.C*var[0]**2 + self.D*u**2\n",
    "        self.differential_operator = lambda J, u, var: (self.H*var[0] + self.M*u)*div(J, var[0]) + (1/2)*self.σ**2*Δ(J, var[0])\n",
    "        self.domain_func = [(lambda var: [var[0]*2-1, var[1]], 128)]\n",
    "        self.boundary_cond_J = [lambda J, var: J - self.R*var[0]**2]\n",
    "        self.boundary_func_J = [(lambda var: [var[0]*2-1, var[1]*0 + 1], 64)]\n",
    "        self.boundary_cond_u = [lambda u, var: torch.clamp(div(u, var[0]), min=0)]\n",
    "        self.boundary_func_u = [(lambda var: [var[0]*2-1, var[1]], 64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "architectural-fruit",
   "metadata": {},
   "outputs": [],
   "source": [
    "LQR_MODEL_CONFIG = {\n",
    "    \"hidden_dim\": 64,\n",
    "    \"learning_rate\": 5e-3,\n",
    "    \"loss_weights\": (1, 1),\n",
    "    \"lr_decay\": 0.99,\n",
    "    \"sampling_method\": \"uniform\",\n",
    "    \"network_type\": \"GRU\",\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"delay_control\": 2,\n",
    "    \"alpha_noise\": 0.1\n",
    "}\n",
    "eq = LQR()\n",
    "model = LQR_MODEL_CONFIG\n",
    "solver = DGMPIASolver(model, eq)\n",
    "loss = np.array(list(solver.train(400)))\n",
    "plot_losses(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electrical-reggae",
   "metadata": {},
   "source": [
    "#### Control function approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ideal-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1, specs=[[{'type': 'surface'}]])\n",
    "xs = np.linspace(-1, 1, 100)\n",
    "ts = np.linspace(0, 1, 100)\n",
    "us_pred = np.array([[solver.u(x, t).item() for x in xs] for t in ts])\n",
    "fig.add_trace(go.Surface(x=xs, y=ts, z=us_pred), row=1, col=1)\n",
    "fig.update_layout(title='Approximation',\n",
    "                  scene = dict(\n",
    "                      xaxis_title=\"x\",\n",
    "                      yaxis_title=\"t\",\n",
    "                      zaxis_title=\"u(x, t)\"),\n",
    "                  margin=dict(l=50, r=50, b=50, t=50))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "municipal-stocks",
   "metadata": {},
   "source": [
    "#### Value function approximation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informational-behalf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1, specs=[[{'type': 'surface'}]])\n",
    "xs = np.linspace(-1, 1, 100)\n",
    "ts = np.linspace(0, 1, 100)\n",
    "us_pred = np.array([[solver.J(x, t).item() for x in xs] for t in ts])\n",
    "fig.add_trace(go.Surface(x=xs, y=ts, z=us_pred), row=1, col=1)\n",
    "fig.update_layout(title='Solution | Approximation',\n",
    "                  scene = dict(\n",
    "                    xaxis_title=\"x\",\n",
    "                    yaxis_title=\"t\",\n",
    "                    zaxis_title=\"J(x, t\"),\n",
    "                  scene2 = dict(\n",
    "                    xaxis_title=\"x\",\n",
    "                    yaxis_title=\"t\",\n",
    "                    zaxis_title=\"J(x, t)\"),\n",
    "                  margin=dict(l=50, r=50, b=50, t=50))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italian-tournament",
   "metadata": {},
   "source": [
    "#### Simulating the Process:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-bubble",
   "metadata": {},
   "source": [
    "Let $(\\Omega, \\mathcal{F}, \\{\\mathcal{F}_t\\}_{t\\in [0, T]}, \\mathbb{P})$. We consider\n",
    "$$\n",
    "\\begin{cases}\n",
    "dX_s = [H_s X_s + M_s u_s] ds + \\sigma_s dW_s, \\; s \\in [0, T] \\\\\n",
    "X_0 = x > 0\n",
    "\\end{cases},\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acting-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "c_xs = np.zeros(n)\n",
    "c_xs[0] = 0.75\n",
    "uc_xs = np.zeros(n)\n",
    "uc_xs[0] = c_xs[0]\n",
    "dt = 1/n\n",
    "ts = [t for t in np.linspace(0, 1, n)]\n",
    "c_cum_cost = np.zeros(n)\n",
    "uc_cum_cost = np.zeros(n)\n",
    "for i in range(n-1):\n",
    "    dW = np.sqrt(dt)*np.random.randn()\n",
    "    c = solver.u(c_xs[i], i*dt).item() #-(1/eq.D)*eq.M*((0.316228*np.exp(12.6491*i*dt) - 99125.6)/(313463 + np.exp(12.6491*i*dt))) *c_xs[i] \n",
    "    uc = 0\n",
    "    c_xs[i+1] = c_xs[i] + (eq.H*c_xs[i] + eq.M*c)*dt + eq.σ*dW\n",
    "    uc_xs[i+1] = uc_xs[i] + (eq.H*uc_xs[i] + eq.M*uc)*dt + eq.σ*dW\n",
    "    c_cum_cost[i+1] = c_cum_cost[i] + eq.C*c_xs[i]**2 + eq.D*c**2\n",
    "    uc_cum_cost[i+1] = uc_cum_cost[i] + eq.C*uc_xs[i]**2 + eq.D*uc**2\n",
    "\n",
    "c_cum_cost[-1] += eq.R*c_xs[-1]**2\n",
    "uc_cum_cost[-1] += eq.R*uc_xs[-1]**2\n",
    "    \n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "fig.add_trace(go.Scatter(x=ts, y=c_xs, mode='lines', name=\"Controlled\", line=dict(color=\"#00e476\")), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=ts, y=uc_xs, mode='lines', name=\"Uncontrolled\", line=dict(color=\"#FFe476\")), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=ts, y=c_cum_cost, mode='lines', showlegend=False, line=dict(color=\"#00e476\")), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=ts, y=uc_cum_cost, mode='lines', showlegend=False, line=dict(color=\"#FFe476\")), row=1, col=2)\n",
    "fig.update_layout(\n",
    "    title=\"Minimise amount of X | Minimise the costs (hold both close to zero)\",\n",
    "    xaxis_title=\"t\",\n",
    "    yaxis_title=\"X\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=14\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "undefined-catch",
   "metadata": {},
   "source": [
    "Example: Assume that the UK is subject to another disease outbreak. Each patient admission costs certain resources. We intend to reduce the amount of people in hospitals as quickly as possible to bound admission costs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opening-massage",
   "metadata": {},
   "source": [
    "### Linear-quadratic control problem N-dimensional (Riccati Equation) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-trail",
   "metadata": {},
   "source": [
    "We consider the same problem with $H_t \\in \\mathbb{R}^{n \\times n}$,\n",
    "$M_t \\in \\mathbb{R}^{n \\times k}$, $\\sigma_t \\in \\mathbb{R}^{n \\times m}$ (for now a scalar), $C_t \\in \\mathbb{R}^{n \\times n}$, $D_t \\in \\mathbb{R}^{k \\times n}$, and $R \\in \\mathbb{R}^{n \\times n}$. We also have, $u(t, X_t) \\in\\mathbb{R}^k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-calibration",
   "metadata": {},
   "source": [
    "Let $(\\Omega, \\mathcal{F}, \\{\\mathcal{F}_t\\}_{t\\in [0, T]}, \\mathbb{P})$. We consider\n",
    "$$\n",
    "\\begin{cases}\n",
    "dX_s = [H_sX_s + M_s u_s] ds + \\sigma_s dW_s, \\; s \\in [0, T] \\\\\n",
    "X_0 = x > 0\n",
    "\\end{cases},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-token",
   "metadata": {},
   "source": [
    "We aim to maximise\n",
    "$$\n",
    "J^u(t, x) := \\mathbb{E}^{t, x} \\Big[ \\int_t^T X_s^T C_s X_s + u_s^T D_s u_s ds + X_T^T R X_T\\Big],\n",
    "$$\n",
    "with $C(t) = C \\leq 0, R \\leq 0$, and $D=D(t) < -\\delta < 0$ given and deterministic ($\\delta > 0$ some constant)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nutritional-translation",
   "metadata": {},
   "source": [
    "We write down the problem in its primal form as\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\partial_t J(t, x) + \\sup_{u} \\Big\\{ \\frac{1}{2} \\sigma^2 \\sum_{1 \\leq i, j \\leq n} \\Delta_{x_i x_j} J(t, x) + [H x + M u]^T \\cdot \\nabla_x J(t, x) + x^T C x + u^T D u \\Big\\} = 0 \\text{ on $[0, T] \\times (0, \\infty)$}\n",
    "\\\\\n",
    "J(T, x) = x^T R x \\text{ $\\forall x \\in \\mathbb{R}$}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulation-package",
   "metadata": {},
   "source": [
    "For now, we will consider the problem without the terminal condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-variance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LQR_N(HBJ):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.H = torch.tensor([[0.1, 0],\n",
    "                              [0.0, 0.1]])\n",
    "        self.M = torch.tensor([[2.0, 0],\n",
    "                              [0.0, 2.0]])\n",
    "        self.C = torch.tensor([[-2.0, 0],\n",
    "                              [0.0, -2.0]])\n",
    "        self.R = torch.tensor([[-0.001, 0],\n",
    "                              [0.0, -0.001]])\n",
    "        self.D = torch.tensor([[-0.2, 0],\n",
    "                              [0.0, -0.2]])\n",
    "        self.σ = 0.1\n",
    "        \n",
    "        self.var_dim_J = 3 # (x, y, t)\n",
    "        self.sol_dim = 2\n",
    "        self.control_vars = [0, 1, 2]\n",
    "        self.cost_function = lambda u, var: (var[:2] |bdotb| (self.C |mdotb| var[:2])) + ((u |bdotm| self.D) |bdotb| u)\n",
    "        self.differential_operator = lambda J, u, var: (((self.H |mdotb| var[:2]) + (self.M |mdotb| u)) |bdotb| D(J, var[:2])) + (1/2)*self.σ**2*sum([div(div(J, var[i]), var[j]) for i, j in product(range(2), range(2))])\n",
    "        self.domain_func = [(lambda var: [var[0]*2-1, var[1]*2-1, var[2]], 128)]\n",
    "        self.boundary_cond_J = [lambda J, var: J - ((var[:2] |bdotm| self.R) |bdotb| var[:2])]\n",
    "        self.boundary_func_J = [(lambda var: [var[0]*2-1, var[1]*2-1, var[2]*0 + 1], 64)]\n",
    "        self.boundary_cond_u = [lambda u, var: torch.clamp(div(u, var[0]), min=0),\n",
    "                               lambda u, var: torch.clamp(div(u, var[1]), min=0)]\n",
    "        self.boundary_func_u = [(lambda var: [var[0]*2-1, var[1]*2-1, var[2]], 32),\n",
    "                               (lambda var: [var[0]*2-1, var[1]*2-1, var[2]], 32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-subdivision",
   "metadata": {},
   "outputs": [],
   "source": [
    "LQR_N_MODEL_CONFIG = {\n",
    "    \"hidden_dim\": 64,\n",
    "    \"learning_rate\": 5e-3,\n",
    "    \"loss_weights\": (1, 1),\n",
    "    \"lr_decay\": 0.99,\n",
    "    \"sampling_method\": \"uniform\",\n",
    "    \"network_type\": \"GRU\",\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"delay_control\": 2,\n",
    "    \"alpha_noise\": 0.1\n",
    "}\n",
    "eq = LQR_N()\n",
    "model = LQR_N_MODEL_CONFIG\n",
    "solver = DGMPIASolver(model, eq)\n",
    "loss = np.array(list(solver.train(500)))\n",
    "plot_losses(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yellow-outline",
   "metadata": {},
   "source": [
    "#### Simulating the Process:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "centered-merit",
   "metadata": {},
   "source": [
    "Let $(\\Omega, \\mathcal{F}, \\{\\mathcal{F}_t\\}_{t\\in [0, T]}, \\mathbb{P})$. We consider\n",
    "$$\n",
    "\\begin{cases}\n",
    "dX_s = [H_sX_s + M_s u_s] ds + \\sigma_s dW_s, \\; s \\in [0, T] \\\\\n",
    "X_0 = x > 0\n",
    "\\end{cases},\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-underground",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 50\n",
    "c_xs = np.zeros((2, n))\n",
    "c_xs[:, 0] = 0.5\n",
    "uc_xs = np.zeros((2, n))\n",
    "uc_xs[:, 0] = c_xs[:, 0]\n",
    "dt = 1/n\n",
    "ts = [t for t in np.linspace(0, 1, n)]\n",
    "c_cum_cost = np.zeros(n)\n",
    "uc_cum_cost = np.zeros(n)\n",
    "for i in range(n-1):\n",
    "    dW = np.sqrt(dt)*np.random.randn(2, 1)\n",
    "    c = np.expand_dims(solver.u(c_xs[0, i], c_xs[1, i], i*dt), axis=1)\n",
    "    uc = np.zeros((2, 1))\n",
    "    c_xs[:, None, i+1] = c_xs[:, None, i] + (eq.H.numpy() @ c_xs[:, None, i] + eq.M.numpy() @ c)*dt + eq.σ*dW\n",
    "    uc_xs[:, None, i+1] = uc_xs[:, None, i] + (eq.H.numpy() @ uc_xs[:, None, i] + eq.M.numpy() @ uc)*dt + eq.σ*dW\n",
    "    c_cum_cost[i+1] = c_cum_cost[i] + c_xs[:, None, i].T @ eq.C.numpy() @ c_xs[:, None, i] + c.T @ eq.D.numpy() @ c\n",
    "    uc_cum_cost[i+1] = uc_cum_cost[i] + uc_xs[:, None, i].T @ eq.C.numpy() @ uc_xs[:, None, i] + uc.T @ eq.D.numpy() @ uc\n",
    "\n",
    "c_cum_cost[-1] += c_xs[:, None, -1].T @ eq.R.numpy() @ c_xs[:, None, -1]\n",
    "uc_cum_cost[-1] += uc_xs[:, None, -1].T @ eq.R.numpy() @ uc_xs[:, None, -1]\n",
    "fig = make_subplots(rows=1, cols=2)\n",
    "fig.add_trace(go.Scatter(x=ts, y=c_xs[0], mode='lines', name=\"Controlled\", line=dict(color=\"#00e476\")), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=ts, y=c_xs[1], mode='lines', showlegend=False, line=dict(color=\"#00e476\")), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=ts, y=uc_xs[0], mode='lines', name=\"Uncontrolled\", line=dict(color=\"#FFe476\")), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=ts, y=uc_xs[1], mode='lines', showlegend=False, line=dict(color=\"#FFe476\")), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=ts, y=c_cum_cost, mode='lines', showlegend=False, line=dict(color=\"#00e476\")), row=1, col=2)\n",
    "fig.add_trace(go.Scatter(x=ts, y=uc_cum_cost, mode='lines', showlegend=False, line=dict(color=\"#FFe476\")), row=1, col=2)\n",
    "fig.update_layout(\n",
    "    title=\"Minimise amount of X | Minimise the costs (hold both close to zero)\",\n",
    "    xaxis_title=\"t\",\n",
    "    yaxis_title=\"X\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=14\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shaped-morgan",
   "metadata": {},
   "source": [
    "### Black-Scholes-Barenblatt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-prototype",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{cases}\n",
    "\\partial_t J(t, x) + \\frac{1}{2} \\text{trace}(\\sigma^2 \\text{diag}(x^2 )\\Delta J(t, x)) + r(\\nabla^T J X - J) = 0 \\text{ on $[0, T] \\times (0, \\infty)$}\n",
    "\\\\\n",
    "J(T, x) = x^2 \\text{ $\\forall x \\in \\mathbb{R}$}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polyphonic-visiting",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_SPACES[\"BSB\"] = {\n",
    "        \"SDE\": lambda X, u, t, dt, dW: torch.einsum(\"bij, bj -> bi\", 0.3*torch.diag_embed(X), dW),\n",
    "        \"terminal_time\": 1.0,\n",
    "        \"N_range\": (30, 31),\n",
    "        \"control\": lambda J, X, t: 0*X[0],\n",
    "        \"domain\": (-np.inf, np.inf)\n",
    "}\n",
    "CONFIG_BSB = {\n",
    "    \"hidden_dim\": 32,\n",
    "    \"learning_rate\": 5e-3,\n",
    "    \"loss_weights\": (1, 2),\n",
    "    \"lr_decay\": 0.99,\n",
    "    \"sampling_method\": \"uniform\",\n",
    "    \"sampling_method_boundary\": \"uniform\", \n",
    "    \"network_type\": \"RES\",\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"method\": \"Galerkin\"\n",
    "}\n",
    "class BSB(PDE):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        r = 0.05\n",
    "        sigma = 0.3\n",
    "        self.var_dim = 2 # var = (x, t)\n",
    "        self.equation = lambda u, var: div(u, var[-1]) + (sigma**2/2)*sum([X**2*Δ(u, X) for X in var[:-1]]) + r*((D(u, var[:-1])|bdotb| var[:-1])- u)\n",
    "        self.domain_func = [(lambda var: [(x-0.5)*4 for x in var[:-1]]+ [var[-1]], 128)]\n",
    "        self.boundary_cond = [lambda u, var: u - (var[:-1] |bdotb| var[:-1])]\n",
    "        self.boundary_func = [(lambda var: [(x-0.5)*4 for x in var[:-1]]+ [var[-1]*0+1], 64)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = BSB()\n",
    "model = CONFIG_BSB\n",
    "solver = DeepPDESolver(model, eq)\n",
    "losses = list(solver.train(800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funded-thirty",
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs = np.convolve(losses, np.ones(10), 'valid') / 10\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_trace(go.Scatter(x=np.arange(len(avgs)), y=avgs, mode='lines', name=\"Error at x=0.1\"), row=1, col=1)\n",
    "fig.update_layout(\n",
    "    title=\"Loss\",\n",
    "    xaxis_title=\"Iterations\",\n",
    "    yaxis_title=\"Loss\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=14\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-cassette",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FBSDEs import FBSDESolver\n",
    "from pdes import FBSDE\n",
    "class BSB(FBSDE):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        r = 0.05\n",
    "        self.h = lambda X, Y, Z, t: r*(Y-torch.einsum(\"bi, bi -> b\", Z, X).unsqueeze(1))\n",
    "        \n",
    "        self.b = lambda X, t: 0.0*X\n",
    "        self.sigma = lambda X, t: 0.3*torch.diag_embed(X)\n",
    "        \n",
    "        self.terminal_condition = lambda X: torch.einsum(\"bi, bi-> b\", X, X).unsqueeze(1)\n",
    "        \n",
    "        self.var_dim = 2\n",
    "        self.terminal_time = 1     \n",
    "        self.init_sampling_func = lambda X: (X-0.5)*2\n",
    "        self.control_noise = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-engagement",
   "metadata": {},
   "outputs": [],
   "source": [
    "BSB_MODEL_CONFIG = {\n",
    "    \"batch_size\": 128,\n",
    "    \"num_discretisation_steps\": 30,\n",
    "    \"hidden_dim\": 64,\n",
    "    \"learning_rate\": 5e-3,\n",
    "    \"lr_decay\": 0.99,\n",
    "    \"network_type\": \"MINI\",\n",
    "    \"optimiser\": \"Adam\"\n",
    "}\n",
    "eq_sim = BSB()\n",
    "solver_sim = FBSDESolver(BSB_MODEL_CONFIG, eq_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 2\n",
    "def J_sol(X, t):\n",
    "    r = 0.05\n",
    "    sigma = 0.3\n",
    "    return np.exp((r + sigma**2)*(1 - t))*np.sum(X**2, axis=-1, keepdims=True)\n",
    "Xs, _, ts = solver_sim.simulate_processes(num_samples)\n",
    "Y_sol = J_sol(Xs, ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-courage",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_preds = np.array([[solver.u(*x_b) for x_b in x] for x in Xs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moral-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_trace(go.Scatter(x=ts[:, 0].flatten(), y=Y_preds[:, 0].flatten(), mode='lines', name=\"Prediction\", line=dict(color=\"#FFe476\")), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=ts[:, 0].flatten(), y=Y_sol[:, 0].flatten(), mode='lines', name=\"Ground truth\", line=dict(color=\"#00e476\")), row=1, col=1)\n",
    "for i in range(1, num_samples):\n",
    "    fig.add_trace(go.Scatter(x=ts[:, i].flatten(), y=Y_preds[:, i].flatten(), mode='lines', showlegend=False, line=dict(color=\"#FFe476\")), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=ts[:, i].flatten(), y=Y_sol[:, i].flatten(), mode='lines', showlegend=False, line=dict(color=\"#00e476\")), row=1, col=1)\n",
    "fig.update_layout(\n",
    "    title=\"Value\",\n",
    "    xaxis_title=\"t\",\n",
    "    yaxis_title=\"J\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=14\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, cols=1)\n",
    "fig.add_trace(go.Scatter(x=ts[:, 0].flatten(), y=Xs[:,0 , 0].flatten(), mode='lines', name=\"Stocks Sample 1\", line=dict(color=\"#FFe476\")), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=ts[:, 0].flatten(), y=Xs[:,1 , 0].flatten(), mode='lines', name=\"Stocks Sample 2\", line=dict(color=\"#11e476\")), row=1, col=1)\n",
    "for i in range(1, num_samples):\n",
    "    fig.add_trace(go.Scatter(x=ts[:, i].flatten(), y=Xs[:, 0, i].flatten(), mode='lines', showlegend=False, line=dict(color=\"#FFe476\")), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=ts[:, i].flatten(), y=Xs[:, 1, i].flatten(), mode='lines', showlegend=False, line=dict(color=\"#11e476\")), row=1, col=1)\n",
    "fig.update_layout(\n",
    "    title=\"Value\",\n",
    "    xaxis_title=\"t\",\n",
    "    yaxis_title=\"J\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=14\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-toddler",
   "metadata": {},
   "source": [
    "### Allen-Cahn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "piano-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_AC = {\n",
    "    \"hidden_dim\": 64,\n",
    "    \"learning_rate\": 5e-3,\n",
    "    \"loss_weights\": (1, 2),\n",
    "    \"lr_decay\": 0.99,\n",
    "    \"sampling_method\": \"gaussian\",\n",
    "    \"sampling_method_boundary\": \"gaussian\",\n",
    "    \"network_type\": \"FF\",\n",
    "    \"optimiser\": \"Adam\",\n",
    "    \"method\": \"Galerkin\"\n",
    "}\n",
    "class AC(PDE):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.var_dim = 20 + 1# var = (x, t)\n",
    "        self.equation = lambda u, var: div(u, var[-1]) + (1/2)*Δ(u, var[:-1]) + u - u**3\n",
    "        self.domain_func = [(lambda var: [np.sqrt(0.3*var[-1])*v for v in var[:-1]] + [0.3*var[-1]], 128)]\n",
    "        self.boundary_cond = [lambda u, var: u - 1/(2+0.4*torch.sum(cat(var[:-1])**2, dim=-1, keepdims=True))]#,\n",
    "                             #lambda u, var: torch.sum(D(u, var[:-1])*self.normal, dim=-1)]\n",
    "        self.boundary_func = [(lambda var:  [np.sqrt(0.3)*v for v in var[:-1]] + [0*var[-1]+0.3], 128)]#,\n",
    "                             #(lambda var: self.sample_boundary(var[:-1]) + [var[-1]*0.3], 64)]\n",
    "        #self.normal = torch.zeros((self.boundary_func[1][1], self.var_dim-1))\n",
    "        \n",
    "    def sample_boundary(self, var):\n",
    "        is_boundary = torch.randint(0, self.var_dim-1, size=(var[-1].shape[0], 1)) # idxs for var_dim\n",
    "        mask = F.one_hot(is_boundary, num_classes=self.var_dim-1).squeeze(1)\n",
    "        not_mask = -(mask-1)\n",
    "        sign = torch.sign(torch.rand(size=(var[-1].shape[0], self.var_dim-1))-0.5) # integers -1, 1\n",
    "        re = [(v-0.5)*self.d*not_mask[:, None, i] + mask[:, None, i]*sign[:, None, i] for i, v in enumerate(var)]\n",
    "        self.normal = mask\n",
    "        return re\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medieval-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq = AC()\n",
    "model = CONFIG_AC\n",
    "solver = DeepPDESolver(model, eq)\n",
    "losses = list(solver.train(500))\n",
    "plot_loss(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from FBSDEs import FBSDESolver\n",
    "from pdes import FBSDE\n",
    "AC_MODEL_CONFIG = {\n",
    "    \"batch_size\": 128,\n",
    "    \"num_discretisation_steps\": 15,\n",
    "    \"hidden_dim\": 128,\n",
    "    \"learning_rate\": 5e-3,\n",
    "    \"lr_decay\": 0.99,\n",
    "    \"network_type\": \"MINI\",\n",
    "    \"optimiser\": \"Adam\"\n",
    "}\n",
    "model = AC_MODEL_CONFIG\n",
    "class AC(FBSDE):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.h = lambda X, Y, Z, t: Y - Y**3\n",
    "        \n",
    "        self.b = lambda X, t: 0.0*X\n",
    "        self.sigma = lambda X, t: torch.diag_embed(X*0+1)\n",
    "        \n",
    "        self.terminal_condition = lambda X: 1/(2+0.4*torch.sum(X**2, dim=-1, keepdims=True))\n",
    "        \n",
    "        self.var_dim = 20\n",
    "        self.terminal_time = 0.3   \n",
    "        self.init_sampling_func = lambda X: X*0\n",
    "        self.control_noise = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_2 = AC()\n",
    "solver_2 = FBSDESolver(model, eq_2)\n",
    "num_samples=5\n",
    "Xs, _, ts = solver_2.simulate_processes(num_samples)\n",
    "final_test_values = 1/(2+0.4*np.sum(Xs[-1]**2, axis=-1, keepdims=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amber-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = np.linspace(0, 0.3, 15)\n",
    "fig = make_subplots(rows=1, cols=1)\n",
    "for j in range(0, num_samples):\n",
    "    xs = np.array([solver.u(*(Xs[i, j]), ts[i]).item() for i in range(15)])\n",
    "    fig.add_trace(go.Scatter(x=ts, y=xs, mode='lines', showlegend=False), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=[0.3]*num_samples, y=final_test_values.flatten(), mode='markers', showlegend=False, marker=dict(\n",
    "            color='LightSkyBlue',\n",
    "            size=10,\n",
    "            line=dict(\n",
    "                color='MediumPurple',\n",
    "                width=2\n",
    "            )\n",
    "        )), row=1, col=1)\n",
    "fig.add_trace(go.Scatter(x=[0.0], y=[0.3083], mode='markers', showlegend=False, marker=dict(\n",
    "            color='LightSkyBlue',\n",
    "            size=10,\n",
    "            line=dict(\n",
    "                color='MediumPurple',\n",
    "                width=2\n",
    "            )\n",
    "        )), row=1, col=1)\n",
    "fig.update_layout(\n",
    "    title=\"Allen-Cahn\",\n",
    "    xaxis_title=\"Iterations\",\n",
    "    yaxis_title=\"Loss\",\n",
    "    font=dict(\n",
    "        family=\"Courier New, monospace\",\n",
    "        size=14\n",
    "    )\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cathedral-mixer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-exchange",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
